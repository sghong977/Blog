---
layout: post
title: Multishot Human Pose
---

I'm trying to extract SMPL parameters on video in a multishot setting. To this end, tracklets are necessary.


### Steps: PHALP setup -> Multishot Human Pose extraction -> select data for training NeRF.


# 1. PHALP setup

### clone PHALP and install
- follow this https://github.com/brjathu/PHALP#installation
- it takes quite a time to solve environment in conda

issues while installing PHALP:
- pip install pyrootutils submitit gdown dill colordict scenedetect pytube
- pip install scikit-learn==0.22.2
- OpenGL: ssh env (without display)
  - install OSMesa https://pyrender.readthedocs.io/en/latest/install/index.html#installmesa
  - apt-get install libexpat1-dev


# 2. multishot human pose setup
- follow this ..

### Demo
python scripts/demo.py video.source=\'"https://www.youtube.com/watch?v=xEH_5T9jMVU"\'

### Notes.
- To extract SMPL by multishot human pose, tracking and identification are needed.
- What about the other SMPL algorithms? SMPL extraction models like ROMP, VIBE...
  - Do they use 2D keypoints?
  - Regression or optimized based?
  - How are they inputs like? sequence or only an image? should be cropped? do they work on multiple people?
